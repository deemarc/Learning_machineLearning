{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression 1\n",
    "\n",
    "Regression is an attemp to find the equation that best fits the data, and be able forecast out a specific value.\n",
    "A linear regression is as the name state, we use a linear equation.\n",
    "\n",
    "In this intro will the tutorial use the data from quandl\n",
    "Quandl is a platform for financial, economic, and alternative data that serves investment professionals.\n",
    "and it as a great api available in python! (so, cool I will try it out more later)\n",
    "\n",
    "to install Quandl api\n",
    "\n",
    "pip install quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "#getting data that grabs the stock price for Alphabet (previously Google), with the ticker of GOOGL:\n",
    "df = quandl.get(\"WIKI/GOOGL\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to understand more about our data frame \n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter\n",
    "\n",
    "That a bit too mucn of an information we have, to see will filter out the data an choose only features we are interst in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Adj. Open    Adj. High     Adj. Low   Adj. Close  Adj. Volume\n",
      "Date                                                                       \n",
      "2004-08-19    50.159839    52.191109    48.128568    50.322842   44659000.0\n",
      "2004-08-20    50.661387    54.708881    50.405597    54.322689   22834300.0\n",
      "2004-08-23    55.551482    56.915693    54.693835    54.869377   18256100.0\n",
      "2004-08-24    55.792225    55.972783    51.945350    52.597363   15247300.0\n",
      "2004-08-25    52.542193    54.167209    52.100830    53.164113    9188600.0\n",
      "2004-08-26    52.637487    54.142132    52.492038    54.122070    7094800.0\n",
      "2004-08-27    54.217364    54.478169    53.008633    53.239345    6211700.0\n",
      "2004-08-30    52.802998    52.908323    51.162935    51.162935    5196700.0\n",
      "2004-08-31    51.318415    52.015567    51.238167    51.343492    4917800.0\n",
      "2004-09-01    51.509003    51.644421    49.989312    50.280210    9138200.0\n",
      "2004-09-02    49.698414    51.343492    49.623182    50.912161   15118600.0\n",
      "2004-09-03    50.631294    51.027517    49.813770    50.159839    5152400.0\n",
      "2004-09-07    50.661387    51.157920    49.959219    50.947269    5847500.0\n",
      "2004-09-08    50.525969    51.674514    50.405597    51.308384    4985600.0\n",
      "2004-09-09    51.408694    51.514019    50.656371    51.313400    4061700.0\n",
      "2004-09-10    50.892099    53.444980    50.806836    52.828075    8698800.0\n",
      "2004-09-13    53.480088    54.372844    53.394825    53.916435    7844100.0\n",
      "2004-09-14    53.886342    56.173402    53.560336    55.917612   10828900.0\n",
      "2004-09-15    55.451172    57.291854    55.270615    56.173402   10713000.0\n",
      "2004-09-16    56.343928    58.079285    55.997860    57.161452    9266300.0\n",
      "2004-09-17    57.387149    58.926902    56.950802    58.926902    9472500.0\n",
      "2004-09-20    58.656066    60.988265    58.565787    59.864797   10628700.0\n",
      "2004-09-21    60.286097    60.396438    58.936933    59.102444    7228700.0\n",
      "2004-09-22    58.906840    60.020277    58.585849    59.373280    7581200.0\n",
      "2004-09-23    59.603992    61.504860    58.691174    60.597057    8535600.0\n",
      "2004-09-24    60.672290    62.242136    60.065416    60.100525    9123400.0\n",
      "2004-09-27    59.965107    60.627150    59.082382    59.313094    7066100.0\n",
      "2004-09-28    60.762568    63.897245    60.291113    63.626409   16929000.0\n",
      "2004-09-29    63.460898    67.719042    63.310433    65.742942   30516400.0\n",
      "2004-09-30    65.150614    66.354831    64.699722    65.000651   13758000.0\n",
      "...                 ...          ...          ...          ...          ...\n",
      "2017-12-22  1070.000000  1071.720000  1067.640000  1068.860000     860800.0\n",
      "2017-12-26  1068.640000  1068.860000  1058.640000  1065.850000     914574.0\n",
      "2017-12-27  1066.600000  1068.270000  1058.380000  1060.200000    1027634.0\n",
      "2017-12-28  1062.250000  1064.840000  1053.380000  1055.950000     982285.0\n",
      "2017-12-29  1055.490000  1058.050000  1052.700000  1053.400000    1156357.0\n",
      "2018-01-02  1053.020000  1075.980000  1053.020000  1073.210000    1555809.0\n",
      "2018-01-03  1073.930000  1096.100000  1073.430000  1091.520000    1550593.0\n",
      "2018-01-04  1097.090000  1104.080000  1094.260000  1095.760000    1289293.0\n",
      "2018-01-05  1103.450000  1113.580000  1101.800000  1110.290000    1493389.0\n",
      "2018-01-08  1111.000000  1119.160000  1110.000000  1114.210000    1148958.0\n",
      "2018-01-09  1118.440000  1118.440000  1108.200000  1112.790000    1335995.0\n",
      "2018-01-10  1107.000000  1112.780000  1103.980000  1110.140000    1027781.0\n",
      "2018-01-11  1112.310000  1114.850000  1106.480000  1111.880000    1102461.0\n",
      "2018-01-12  1110.100000  1131.300000  1108.010000  1130.650000    1914460.0\n",
      "2018-01-16  1140.310000  1148.880000  1126.660000  1130.700000    1783881.0\n",
      "2018-01-17  1136.360000  1139.320000  1123.490000  1139.100000    1353097.0\n",
      "2018-01-18  1139.350000  1140.590000  1124.460000  1135.970000    1333633.0\n",
      "2018-01-19  1138.030000  1143.780000  1132.500000  1143.500000    1418376.0\n",
      "2018-01-22  1143.820000  1166.880000  1141.820000  1164.160000    1437954.0\n",
      "2018-01-23  1170.620000  1178.510000  1167.250000  1176.170000    1832126.0\n",
      "2018-01-24  1184.980000  1187.050000  1167.400000  1171.290000    1818182.0\n",
      "2018-01-25  1180.710000  1185.000000  1171.840000  1182.140000    1398961.0\n",
      "2018-01-26  1187.530000  1187.560000  1168.030000  1187.560000    1981476.0\n",
      "2018-01-29  1188.000000  1198.000000  1184.060000  1186.480000    1533931.0\n",
      "2018-01-30  1177.720000  1187.930000  1174.510000  1177.370000    1792602.0\n",
      "2018-01-31  1183.810000  1186.320000  1172.100000  1182.220000    1643877.0\n",
      "2018-02-01  1175.990000  1187.450000  1169.360000  1181.590000    2774967.0\n",
      "2018-02-02  1127.420000  1131.300000  1111.170000  1119.200000    5798880.0\n",
      "2018-02-05  1100.610000  1114.990000  1056.740000  1068.760000    3742469.0\n",
      "2018-02-06  1033.980000  1087.380000  1030.010000  1084.430000    3732527.0\n",
      "\n",
      "[3390 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[['Adj. Open',  'Adj. High',  'Adj. Low',  'Adj. Close', 'Adj. Volume']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "\n",
    "Quote from tutorial:\n",
    "\"Not all of the data you have is useful, and sometimes you need to do further manipulation on your data to make it even more valuable before feeding it through a machine learning algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19   50.322842  8.441017    0.324968   44659000.0\n",
      "2004-08-20   54.322689  8.537313    7.227007   22834300.0\n",
      "2004-08-23   54.869377  4.062357   -1.227880   18256100.0\n",
      "2004-08-24   52.597363  7.753210   -5.726357   15247300.0\n",
      "2004-08-25   53.164113  3.966115    1.183658    9188600.0\n"
     ]
    }
   ],
   "source": [
    "# high low percentage\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Low']) / df['Adj. Low'] * 100.0\n",
    "# percentage chage on each day\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n",
    "df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to use later\n",
    "df.to_pickle('wiki-GOOGL-df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19   50.322842  8.441017    0.324968   44659000.0\n",
      "2004-08-20   54.322689  8.537313    7.227007   22834300.0\n",
      "2004-08-23   54.869377  4.062357   -1.227880   18256100.0\n",
      "2004-08-24   52.597363  7.753210   -5.726357   15247300.0\n",
      "2004-08-25   53.164113  3.966115    1.183658    9188600.0\n"
     ]
    }
   ],
   "source": [
    "# load the data frame from pickle\n",
    "df = pd.read_pickle('wiki-GOOGL-df.pkl')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deemarc\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# library need from doing machine learning's regression problem\n",
    "import quandl, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " forecasting out the price, our label, the thing we're hoping to predict, is actually the future price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the next closing price\n",
    "forecast_col = 'Adj. Close'\n",
    "\n",
    "# for missing data 'NaN' we replace it -99999 which will be treat as  outlier \n",
    "df.fillna(value=-99999, inplace=True)\n",
    "\n",
    "#forcasting length: 1% of the data length\n",
    "forecast_out = int(math.ceil(0.01 * len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df[forecast_col].shift(-forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any data row that still have NaN\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356, 4)\n",
      "(3356,)\n",
      "[[  5.43226889e+01   8.53731343e+00   7.22700723e+00   2.28343000e+07]\n",
      " [  5.48693765e+01   4.06235672e+00  -1.22788010e+00   1.82561000e+07]\n",
      " [  5.25973630e+01   7.75321039e+00  -5.72635743e+00   1.52473000e+07]\n",
      " [  5.31641125e+01   3.96611475e+00   1.18365788e+00   9.18860000e+06]\n",
      " [  5.41220696e+01   3.14351233e+00   2.82039066e+00   7.09480000e+06]\n",
      " [  5.32393448e+01   2.77225849e+00  -1.80388529e+00   6.21170000e+06]\n",
      " [  5.11629351e+01   3.41143025e+00  -3.10600304e+00   5.19670000e+06]\n",
      " [  5.13434924e+01   1.51722788e+00   4.88663018e-02   4.91780000e+06]\n",
      " [  5.02802102e+01   3.31092606e+00  -2.38558909e+00   9.13820000e+06]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.drop(['label'],1))\n",
    "y = np.array(df['label'])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41810563  4.38757624  4.82702292  1.79774234]\n",
      " [-1.41582954  1.31020692 -0.8023334   1.24526328]\n",
      " [-1.42528886  3.84835881 -3.79746873  0.8821732 ]\n",
      " [-1.42292925  1.24402257  0.80329493  0.15103325]\n",
      " [-1.41894089  0.67832962  1.89304948 -0.10163825]\n",
      " [-1.42261603  0.42302321 -1.18584395 -0.20820726]\n",
      " [-1.43126097  0.86257328 -2.05280817 -0.33069344]\n",
      " [-1.43050924 -0.44004496  0.0477383  -0.36434999]\n",
      " [-1.43493612  0.79345786 -1.57314869  0.14495118]]\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "X = preprocessing.scale(X)\n",
    "print(X[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data from traning and testing, and also shuffle your data\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "# use Support Vector Regression as a classifier\n",
    "clf = svm.SVR()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827120119845\n"
     ]
    }
   ],
   "source": [
    "# test it out !\n",
    "confidence = clf.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try another classifier\n",
    "clf2 = LinearRegression(n_jobs=-1) # n_jobs=-1 to use all available thread\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976478941805\n"
     ]
    }
   ],
   "source": [
    "# test it out !\n",
    "confidence = clf2.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear 0.975192675228\n",
      "poly 0.656920050119\n",
      "rbf 0.827120119845\n",
      "sigmoid 0.899801188385\n"
     ]
    }
   ],
   "source": [
    "#try out some other kernel\n",
    "for k in ['linear','poly','rbf','sigmoid']:\n",
    "    clf = svm.SVR(kernel=k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    confidence = clf.score(X_test, y_test)\n",
    "    print(k,confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
